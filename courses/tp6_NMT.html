<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<!-- saved from url=(0072)https://cservan.github.io/website/tp4_traduction.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <title>Demo 6: Neural Machine Translation</title>
<body>

<center>
  <h1>Demo 6: Neural Machine Translation</h1>
  <h3 align="center">Christophe Servan (inspired from <a href="https://colab.research.google.com/drive/1tHKHt0Yl8HDQJNW3MLWnA0SMEnnx6ZVu#scrollTo=TCA2nZBLXH1r">tutorial OpenNMT</a>)</h3>
</center>

<!----------------------------------------------------------------------------->
<hr>

<p>In this session, we propose to create a very first model for Neural Machine Translation</p>

<p>Creating a translation system from a parallel corpus is a resource-intensive process (processor, memory, GPU). 
Even with a small corpus like the one we are going to use, the whole system training can take several minutes or even one to two hours. 
The OpenNMT system provides optimized tools to perform this training, but it contains some problems and/or features to be known. 
Feel free to manually check the result of each step and ask questions if there is an error when running a script.
</p>
<hr>
<!----------------------------------------------------------------------------->



<h2>Toolkits</h2>

<ul>
  <li>OpenNMT: <pre> 
  python3 -m pip install OpenNMT-tf
  </pre></li>
  <li>OpenNMT: <pre> 
  python3 -m pip install subword-nmt
  </pre></li>
</ul>

<hr>
<h2>Data</h2>
<ul>
  <li>Parallel corpora is <a href="https://cservan.github.io/website/data/tp_NMT_files.tgz">here</a>) :</li>
	<ul>
	<li>English-French medical training corpus: European Medicines Agency (noted "EMEA_train")</li>
	<li>English-French news training corpus: Europarl V7 (noted ep7_train)</li>
	</ul>
  <li>Development/validation corpora:</li>
        <ul>
        <li>EMEA_dev</li>
        <li>ep7_dev</li>
        </ul>
  <li>  ...and evaluation:</li>
        <ul>
        <li>EMEA_tst</li>
        <li>ep7_tst</li>
        </ul>        
</ul>

<hr>


        <h2>Report
        </h2>
        <p>This is the final report, you have to send me back before <b>July, 30th 11:59pm</b> in <b>PDF</b> format
        at christophe_dot_servan_at_epita_dot_fr </p>
        <p>
        <em>Info:</em>
        </p><ul>
                <li>If you have some issues, feel free ton contact me by mail, I'll answer you as fast as possible.
                </li><li>As this is the final report, delays will be penalized (the more the later).
                </li><li>The mark obtained to this report will be the one for the whole course.
        </li></ul>
        <p></p>
        <hr>

<h2>To do</h2>
<ol>
You will perform the following steps:


<h3>Cleaning</h3>
<p>
The collected data must be refined. The refinement process includes sorting sentences by corpus in both languages, and eliminating noise such as special characters.
</p>

<h3>Subword Tokenization</h3>
<p>
Refine spacing using the POS tagger or segmenter for each language. English may have refinement issues in upper / lower case. After the spacing is refined, use Byte Pair Encoding (BPE) using public tools such as Subword or WordPiece. This allows you to perform additional segments and construct a vocabulary list. At this time, the segmented models learned for the BPE segment should be kept for future use.
</p>

<h3>Train</h3>
<p>
Train the neural model using prepared datasets. Depending on the amount, you can train with a single GPU, or use multiple GPUs in parallel to reduce training time.
</p>

<h3>Translate</h3>
<p>
Now that the model has been created, you can start translating.
</p>

<h3>Detokenization</h3>
<p>
Even after the translation process is finished, it is still in a segment, so it is different from the actual sentence structure used by real people. Thus, when you perform a detoxification process, it is returned in the form of the actual sentence.
</p>

<h3>Evaluating</h3>
<p>
Quantitative evaluation is performed on the sentence thus obtained. BLEU is a quantitative evaluation method for machine translation. You can see which model is superior by comparing it to the BLEU score you are comparing.
</p>

  <p>You will have to re-use the tokenization, Dans ce TP vous allez devoir utiliser vos connaissances acquises lors du premier TP pour effectuer la segmentation (ou <em>tokenization</em> en anglais) des corpus puis vous allez créer les modèles de traductions (table de traduction + modèle de réordonnancement) et les modèles de langage.</p>
<!-- <ol> -->
</ol>

<hr>
<h2>Details</h2>
<ol>
  <h3>I. Tokenization</h3>
  
    <p>Concatenate all the French training file into <tt>train.fr</tt> and the English training file into <tt>train.en</tt> </p>

<p>We will be working with some example data in <tt>my_model_directory/</tt> folder. ​ The data consists of parallel source (src) and target (tgt) data containing one sentence per line with tokens separated by a space: ​
<ul>
    <li>EMEA_train.fr</li>
    <li>EMEA_train.en</li>
    <li>ep7_train.fr</li>
    <li>ep7_train.en</li>
    <li>ep7_dev.fr</li>
    <li>ep7_dev.en</li>
</ul>

Train data and validataion data are required for machine translation training. ​ Validation files are required and used to evaluate the convergence of the training. It usually contains no more than 5000 sentences.
</p>
    <p>We use Byte Pair Encoding for Subword Tokenization <a href=https://www.aclweb.org/anthology/P16-1162>https://www.aclweb.org/anthology/P16-1162</a></p>
<ul>
<li>i => input</li>
<li>o => Output(*.code)</li>
<li>s => Symbol (Usually use 32000 but we will use a lower value: 16k to speed up the training)</li>
<li>learn-bpe ==> make code</li>
<li>apply-bpe ==> apply subwordTokenization</li>
<li>src-train, src-val,test => Need to apply src.code</li>
<li>tgt-train, tgt-val => Need to apply tgt.code </li>
<li>command lines:</br>

<tt>cat EMEA_train.fr ep7_train.fr &gt; train.fr </tt></br>
<tt>cat EMEA_train.en ep7_train.en &gt; train.en </tt></br>
<tt>mkdir -pv my_model_directory </tt></br>
<tt>subword-nmt learn-bpe  -s 16000 &lt; train.fr &gt; my_model_directory/fr.code </tt></br>
<tt>subword-nmt learn-bpe  -s 16000 &lt; train.en &gt; my_model_directory/en.code </tt></br>
<tt>subword-nmt apply-bpe -c  fr.code &lt; train.fr &gt; my_model_directory/train.fr.bpe</tt></br>
<tt>subword-nmt apply-bpe -c  en.code  &lt; train.en &gt; my_model_directory/train.en.bpe</tt></br>
<tt>subword-nmt apply-bpe -c  fr.code &lt; EMEA_dev.fr &gt; my_model_directory/EMEA_dev.fr.bpe</tt></br>
<tt>subword-nmt apply-bpe -c  en.code  &lt; EMEA_dev.en &gt; my_model_directory/EMEA_dev.en.bpe</tt></br>
<tt>subword-nmt apply-bpe -c  fr.code &lt; ep7_dev.fr &gt; my_model_directory/ep7_dev.fr.bpe</tt></br>
<tt>subword-nmt apply-bpe -c  en.code  &lt; ep7_dev.en &gt; my_model_directory/ep7_dev.en.bpe</tt></br>
<tt>subword-nmt apply-bpe -c  fr.code &lt; EMEA_tst.fr &gt; my_model_directory/EMEA_tst.fr.bpe</tt></br>
<tt>subword-nmt apply-bpe -c  en.code  &lt; EMEA_tst.en &gt; my_model_directory/EMEA_tst.en.bpe</tt></br>
<tt>subword-nmt apply-bpe -c  fr.code &lt; ep7_tst.fr &gt; my_model_directory/ep7_tst.fr.bpe</tt></br>
<tt>subword-nmt apply-bpe -c  en.code  &lt; ep7_tst.en &gt; my_model_directory/ep7_tst.en.bpe</tt></br>
</li>
</ul>
<h4>Build Vocab</h4>

<tt>onmt-build-vocab --size 50000 --save_vocab my_model_directory/vocab.fr my_model_directory/train.fr.bpe</tt></br>

<tt>onmt-build-vocab --size 50000 --save_vocab my_model_directory/vocab.en my_model_directory/train.en.bpe</tt></br>

<h3>II. Data file configuration</h3>
Put these lines into the <tt>data.yml</tt> file
<pre>
model_dir: my_model_directory/run/

data:
  train_features_file: my_model_directory/train.fr.bpe
  train_labels_file: my_model_directory/train.en.bpe
  eval_features_file: my_model_directory/ep7_dev.fr.bpe
  eval_labels_file: my_model_directory/ep7_dev.en.bpe
  source_vocabulary: my_model_directory/vocab.fr
  target_vocabulary: my_model_directory/vocab.en

train:
  batch_size: 1024
  save_checkpoints_steps: 1000
  maximum_features_length: 50
  maximum_labels_length: 50

eval:
    eval_delay: 3600  # Every 1 hour
    external_evaluators: BLEU
    export_on_best: BLEU
infer:
    batch_size: 32
</pre>
<p>Note: change the value of the batch size if you don't have enough memory</p>
 <h3> III.  Train the Transformer model</h3>
 
 <pre>
 onmt-main train --with_eval --model_type Transformer --auto_config --config data.yml [--num_gpus 1] # if you have GPU
 </pre>
  <h3> IV.  Translate the model obtained </h3>
 <pre>
  onmt-main infer --auto_config  --config data.yml --features_file my_model_directory/ep7_tst.fr.bpe --predictions_file my_model_directory/ep7_hyp.en.bpe --checkpoint_path my_model_directory/run/model.ckpt-YOUR_MODEL
 </pre>
  
  
  <h3>V. Detokenization</h3>
<p>
Even after the translation process is finished, it is still in a segment, so it is different from the actual sentence structure used by real people. Thus, when you perform a detoxification process, it is returned in the form of the actual sentence.</p>
<p> We Use "sed" for BPE Detokenization</p>
<pre>
cat my_model_directory/ep7_hyp.en.bpe | sed "s/@@ //g" > my_model_directory/ep7_hyp.en
</pre>

<h3>VI. Evaluation Using BLEU</h3>
<p>
Quantitative evaluation is performed on the sentence thus obtained. BLEU is a quantitative evaluation method for machine translation. You can see which model is superior by comparing it to the BLEU score you are comparing.
</p>
<a href=https://www.aclweb.org/anthology/P02-1040>https://www.aclweb.org/anthology/P02-1040</a>
<pre>
perl  OpenNMT-tf/third_party/multi-bleu.perl my_model_directory/ep7_tst.en < my_model_directory/ep7_hyp.en
</pre>
</ol>

<hr>
<h2>Exercice 1</h2>
<ol>
    <p>Q1: translate and evaluate the EMEA_tst file. What is the BLEU score?</p>
    <p>Q2: re-launch the training process by using EMEA_dev file as valid file and re-translate and re-evaluate the EMEA_tst and ep7_tst files. Is there a strong difference between the two experiments?</p>
    <p>Q3: Re-evaluate all the translations using other metrics often used for Machine Translation. Chose two other metrics, score the files, explain why you chose them and explain them.</p>
</ol>
<hr>
<p><b>THE END!</b></p>

</body></html>